# train.py Config - Training
train:
  # For datasets, please pass atleast 1 value. If no datasets exist, pass "" as path for images.
  # Synthetic datasets with ground truth depths
  datasetsTrain:
      - images: './data/train/rgb-imgs'
        depths: './data/train/depth-imgs-rectified'
     

  # Synthetic datasets with ground truth depths - 10% split of train
  datasetsVal:
      - images: './data/val/rgb-imgs'
        depths: './data/val/depth-imgs-rectified'

  # Real Images (no ground truth depths)
  datasetsTestReal:
      - images: './data/test/rgb-imgs'
        depths: './data/test/depth-imgs-rectified'

  # Synthetic datasets with ground truth depths - Used as test set
  datasetsTestSynthetic:
      - images: './data/test/rgb-imgs'
        depths: './data/test/depth-imgs-rectified'

  
  # Training/Validation Params
  model: "densedepth" # Possible values: ['densedepth']
  batchSize: 4
  validationBatchSize: 4
  testBatchSize: 4
  numEpochs: 1
  imgHeight: 256
  imgWidth: 256
  numInputChannels: 3 # Num of channels in input image. RGB = 3 channels, Grayscale = 1 channel.
  numWorkers: 1 # Num of workers used in the dataloader
  logsDir: "logs" # Directory where logs of each exp will be saved.
  lossFunc: "cosine" # Possible values: ['cosine', 'radians']
  percentageDataForTraining: 1.0 # The percentage of images in dataset to be used for training.
  percentageDataForValidation: 1.0

  
  continueTraining: False # If true, continue training from a checkpoint
  pathPrevCheckpoint: "./logs/exp-000/checkpoints/checkpoint-epoch-0000.pth" # Path to .pth checkpoint file to load to continue training from
  initOptimizerFromCheckpoint: False # Re-Initialize optimizer's state from checkpoint. NOTE: when this is enabled, value of learningRate will be overridden with value from checkpoint.
  loadEpochNumberFromCheckpoint: False # If true, the epoch/iter numbering will start from the checkpoint's last epoch num.

  saveImageInterval: 1 # Log output images to tensorboard every saveImageInterval epochs
  saveImageIntervalIter: 100 # Every N iterations, log output images to tensorboard
  testInterval: 1 # Run on test set every nTestInterval epochs. Keep at 0 to skip tests.
  saveModelInterval: 5 # Save the model checkpoints every N epochs

  # Optimizer Params
  optimAdam:
    learningRate: 0.0001
    weightDecay: 0 # Other values: 0.0001
  optimSgd:
    learningRate: 1e-6
    momentum: 0.9
    weight_decay: 5e-4
  lrScheduler: "StepLR" # Possible Values: ['', 'StepLR', 'ReduceLROnPlateau'] 
  lrSchedulerStep:
    step_size: 7
    gamma: 0.1
  lrSchedulerPlateau:
    factor: 0.8
    patience: 25
    verbose: True

# eval.py Config - Validation/Testing Inference
eval:
  # Synthetic datasets with ground truth depths
  # Used as validation set
  datasetsSynthetic:
    - images: './data/val/rgb-imgs'
      depths: './data/val/depth-imgs-rectified'

  # Datasets of real images, no depths available
  # Used as Test set
  datasetsReal:
    # - images: "datasets-transparent/studio_pics_sorted/selected_test/d415"
    #   depths: "datasets-transparent/studio_pics_sorted/selected_test/d415"
    # - images: "datasets-transparent/studio_pics_sorted/selected_test/d435"
    #   depths: "datasets-transparent/studio_pics_sorted/selected_test/d435"
    # - images: "datasets-transparent/studio_pics_sorted/selected_val/d435"
    #   depths: "datasets-transparent/studio_pics_sorted/selected_val/d435"

 
  # Params
  model: "densedepth" # Possible values: ['densedepth']
  batchSize: 2
  imgHeight: 256
  imgWidth: 256
  os: 8
  numWorkers: 1 # Num of workers used in the dataloader
  pathWeightsFile: "./logs/exp-000/checkpoints/checkpoint-epoch-0000.pth" # Path to the checkpoint to be loaded
  resultsDir: "./data/results"

